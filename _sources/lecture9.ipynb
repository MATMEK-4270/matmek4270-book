{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 9\n",
    "\n",
    "## Function approximation with global functions II\n",
    "\n",
    "Legendre polynomials $\\{P_j(x)\\}_{j=0}^N, x \\in [-1, 1]$ form a basis for the space of all polynomials with order smaller than or equal to $N$. This space is normally denoted as $\\mathbb{P}_N$. The Legendre polynomials are a very good basis because they are orthogonal in $L^2([-1, 1])$ \n",
    "\n",
    "$$\n",
    "\\left(P_i, P_j\\right)_{L^2([-1,1])} = \\frac{2}{2i+1}\\delta_{ij}\n",
    "$$\n",
    "\n",
    "and very well suited for approximating other smooth functions. However, there is yet another polynomial basis that is generally considered to be even better than Legendre: The Chebyshev polynomials!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chebyshev polynomials\n",
    "\n",
    "The Chebyshev polynomials can be defined in their most simple and useful form as\n",
    "\n",
    "$$\n",
    "T_k(x) = \\cos(k \\cos^{-1}(x)), \\quad k \\in (0, 1, \\ldots, N).\n",
    "$$(eq-chebT)\n",
    "\n",
    "Now this does not look like polynomials at all, it looks like cosine functions. However, an alternative definition is the recursive form\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T_0(x) &= 1, \\\\\n",
    "T_1(x) &= x, \\\\\n",
    "T_2(x) &= 2x^2-1, \\\\\n",
    "&\\vdots \\\\\n",
    "T_{j+1}(x) &= 2xT_{j}(x) - T_{j-1}(x)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The first 5 polynomials are shown in the figure below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x = sp.Symbol('x')\n",
    "plt.figure(figsize=(6, 4))\n",
    "xj = np.linspace(-1, 1, 100)\n",
    "legend = []\n",
    "for n in range(5):\n",
    "    plt.plot(xj, np.cos(n*np.arccos(xj)))\n",
    "    legend.append(f'$P_{n}(x)$')\n",
    "plt.legend(legend);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is noteworthy that all polynomials oscillate between $-1$ and $1$. And all polynomials ($j>0$) have maximum and minimum values of exactly 1 and -1. In fact, all the $N+1$ extrema points of $T_N(x)$ are\n",
    "\n",
    "$$\n",
    "x_j = \\cos\\left(\\frac{j \\pi}{N}\\right), \\quad j \\in (0, 1, \\ldots, N),\n",
    "$$(eq-chebpoints)\n",
    "\n",
    "which are called the Chebyshev points. Another set of points are all the roots of $T_N(x)$\n",
    "\n",
    "$$\n",
    "x_j = \\cos\\left( \\frac{(2j+1)\\pi}{2N}\\right), \\quad j \\in (0, 1, \\ldots, N-1).\n",
    "$$(eq-chebroots)\n",
    "\n",
    "The roots are often called the Chebyshev-Gauss points because of their importance in numerical integration through [Gaussian quadrature](https://en.wikipedia.org/wiki/Gaussian_quadrature).\n",
    "\n",
    "```{note}\n",
    "Both the roots and the extrema are cosine functions. If we choose $x=\\cos \\theta, \\, \\theta \\in [0, 2\\pi]$, then Eq. {eq}`eq-chebT` becomes\n",
    "$$\n",
    "T_k(x) = T_k(\\cos \\theta) =  \\cos\\left(k \\theta \\right) \n",
    "$$\n",
    "```\n",
    "\n",
    "Chebyshev polynomials are very efficient to work with because of the link to the cosine function. The polynomials are also extremely efficient basis functions.\n",
    "\n",
    "The only disadvantage of Chebyshev polynomials is that they are only orthogonal in a special weighted inner product space. We define the weighted $L^2_{\\omega}(\\Omega)$ inner product as\n",
    "\n",
    "$$\n",
    "(f, g)_{L^2_{w}(\\Omega)} = \\int_{\\Omega} f(x)g(x)\\omega(x)dx\n",
    "$$\n",
    "\n",
    "where $\\omega(x)$ is a special weight function. For Chebyshev polynomials defined in $\\Omega = [-1, 1]$ we use the weight function $\\omega(x) = 1/\\sqrt{1-x^2}$. For simplicity we will write the weighted inner product as $(f, g)_{\\omega}$.\n",
    "\n",
    "Other than the special definition of the inner product, the usage is exactly as for the Legendre polynomials. We have the function space $\\text{T}_N = \\text{span}\\{T_j\\}_{j=0}^N$ which is a basis for $\\mathbb{P}_N$ on $[-1, 1]$. And to find $u_N \\in \\text{T}_N$ means that we are looking for a function\n",
    "\n",
    "$$\n",
    "u_N(x) = \\sum_{j=0}^N \\hat{u}_j T_j(x),\n",
    "$$\n",
    "\n",
    "where $\\{\\hat{u}_j\\}_{j=0}^N$ as before are the unknown expansion coefficients.\n",
    "\n",
    "The Galerkin method to approximate a function $u(x)$ for $x\\in [a, b]$ becomes: find $u_N \\in \\text{T}_N$ such that\n",
    "\n",
    "$$\n",
    "(u-u_N, v)_{\\omega} = 0 \\quad \\forall \\, v \\in \\text{T}_N.\n",
    "$$\n",
    "\n",
    "For a problem where $x \\in [a, b]$ we need to map the true domain to the reference domain, exactly like for the Legendre polynomials. We start with the general definition\n",
    "\n",
    "$$\n",
    "(u(x)-u_N(x), \\psi_i(x))_{\\omega} = \\int_{a}^b (u(x)-u_N(x)) \\psi_i(x) \\omega(x) dx = 0, \\quad \\forall i \\in (0, 1, \\ldots, N)\n",
    "$$\n",
    "\n",
    "which is just a regular Galerkin method using a weighted inner product. But now we introduce the mapped functions $\\psi_j(x) = T_j(X), \\omega(x) = \\tilde{\\omega}(X) = 1/\\sqrt{1-X^2}$ and a change of variables for the integration. This leads to\n",
    "\n",
    "$$\n",
    "\\sum_{j=0}^N \\int_{-1}^1 T_j(X)  T_i(X) \\tilde{\\omega}(X)\\, \\frac{dx}{dX} \\, dX \\, \\hat{u}_j =  \\int_{-1}^1 u(x(X)) T_i(X) \\tilde{\\omega}(X) \\, \\frac{dx}{dX} \\, dX, \\quad \\forall i \\in (0, 1, \\ldots, N)\n",
    "$$\n",
    "\n",
    "As for Legendre the $dx/dX$ term is constant and can be neglected. We get\n",
    "\n",
    "$$\n",
    "\\sum_{j=0}^N  (T_j(X), T_i(X))_{L_{\\omega}^2([-1,1])} \\, \\hat{u}_j = (u(x(X)), T_i(X))_{L_{\\omega}^2([-1,1])}\n",
    "$$(eq-cheb0)\n",
    "\n",
    "The Chebyshev polynomials are orthogonal in $L^2_{\\omega}([-1, 1])$\n",
    "\n",
    "$$\n",
    "\\left(T_j, T_i \\right)_{\\omega} = \\frac{c_i \\pi}{2}\\delta_{ij},\n",
    "$$\n",
    "\n",
    "where $c_0=2$ and $c_i = 1$ for $i > 0$. Using the orthogonality in {eq}`eq-cheb0` we get the Chebyshev expansion coefficients\n",
    "\n",
    "$$\n",
    "\\hat{u}_i = \\frac{2}{c_i \\pi}\\left(u(x(X)), T_i(X)\\right)_{\\omega}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bookmatmek4270",
   "language": "python",
   "name": "bookmatmek4270"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
